{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import water supply data & create supply table\n",
    "Here we download the raw supply data for years 2000, 2005, and 2010 from from downscaled CMIP5 hydrology projections ([link](http://gdo-dcp.ucllnl.org/downscaled_cmip_projections/techmemo/BCSD5HydrologyMemo.pdf)).\n",
    "\n",
    "These data include monthly estimates of runoff, precipitation, evapotranspiration, and soil moisture content at a 1/8th degree spatial resolution across the US for the period of 1950 to 2099. Estimates are provided for 21 different climate projection ensembles applied to the Variable Infiltration Capacity (VIC) Macroscale Hydrologic Model ([link](http://vic.readthedocs.io/en/master/)); see the PDF document for a complete list. For demonstration purposes, this project uses the National Center for Atmospheric Research CCSM4 2.6 projection ensembles as the base data for water supply figures. \n",
    " \n",
    "The steps involved include:\n",
    "\n",
    "* Download monthly runoff (total_runoff), precipitation (pr), evapotranspiration (et), and soil moisture content (smc) data, in NetCDF format, from a central data repository ([link](ftp://gdo-dcp.ucllnl.org/pub/dcp/archive/cmip5/hydro/BCSD_mon_VIC_nc/ccsm4_rcp26_r1i1p1/)) for a given sample year (2000, 2005, and 2010).\n",
    "\n",
    "* For each year and parameter combination:\n",
    "\n",
    "    * Extract the monthly data from the downloaded NetCDF files into 4-dimensional NumPy arrays (time, parameter value, latitude, longitude).\n",
    "\n",
    "    * Collapse the time dimension (months) into annual sums, resulting in a 3-dimensional array for each parameter, i.e. a single annual value for each 1/8th degree coordinate pair: rows = latitudes, columns = longitudes.\n",
    "\n",
    "    * Re-lable columns as longitude values and insert a column of latitude values. Then melt the table into a listing of lat, long, and value. \n",
    "\n",
    "    * Combines these 3-dimensional arrays, one for each parameter, into a single data frame listing parameter value, latitude, and longitude. \n",
    "\n",
    "    * Spatially join state FIPS codes to the data frame, using a county shapefile stored in the data folder. \n",
    "\n",
    "* Summarize supply values on FIPS to create a table that can be joined to other county level data:\n",
    "\n",
    "| YEAR | FIPS | Precip | ET | Runoff | SoilMoisture | TotalSupply | \n",
    "| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| 2000 | 01001 | 0 | 0 | 0 | 0 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import sys, os, glob, time, datetime, urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting record FIPS data\n"
     ]
    }
   ],
   "source": [
    "#Grab the FIPS data and create a dataframe from it\n",
    "print \"Getting record FIPS data\"\n",
    "fipsURL = \"https://raw.githubusercontent.com/johnpfay/USWaterAccounting/VersionZero/Data/FIPS.csv\"\n",
    "dfFIPS = pd.read_csv(fipsURL,dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the output file\n"
     ]
    }
   ],
   "source": [
    "#Initialize the output file and write the header line\n",
    "print \"Initializing the output file\"\n",
    "outFile = open(\"..\\..\\Scratch\\HydroData.csv\",'wt')\n",
    "outFile.write(\"YEAR,LONGITUDE,LATITUDE,COFIPS,STFIPS,RUNOFF,PRECIP,ET,SME\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tmpData.nc', <mimetools.Message instance at 0x08B43878>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get precip data\n",
    "year = 2000\n",
    "baseURL2 = 'ftp://gdo-dcp.ucllnl.org/pub/dcp/archive/cmip5/hydro/BCSD_mon_forc_nc/ccsm4_rcp26_r1i1p1/'\n",
    "prURL = baseURL2 + \"conus_c5.ccsm4_rcp26_r1i1p1.monthly.pr.{}.nc\".format(year)\n",
    "urllib.urlretrieve(prURL,\"tmpData.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a netCDF object\n",
    "nc = netCDF4.Dataset(\"tmpData.nc\",mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the parameter name and its values (the last dimension in the nc object)\n",
    "param_name = nc.variables.keys()[-1]\n",
    "param_vals = nc.variables.values()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dataframes of latitude and longitude values\n",
    "dfLats = pd.DataFrame(nc.variables['latitude'][:])\n",
    "dfLons = pd.DataFrame(nc.variables['longitude'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a dataframe of the parameter values, summed for all month records\n",
    "# The columns here are longitudes and rows are latitudes\n",
    "dfParam = pd.DataFrame(param_vals[:,:,:].sum(axis=0))\n",
    "dfParam.columns = dfLons[0].values.tolist()\n",
    "dfParam['LAT'] = dfLats[0].values.tolist()\n",
    "df = pd.melt(dfParam,id_vars=['LAT'],var_name='LON',value_name=param_name)\n",
    "df.dropna(inplace=True)\n",
    "df.to_csv(\"foo.csv\",index_name=\"OID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the year to process\n",
    "year = 2000\n",
    "print \"Processing year {}\".format(year)\n",
    "\n",
    "#Get urls for NCAR 2.6 scenario ensembles: runoff(ro), precipitation(pr), evapotranspiration(et), soil moisture (sm)\n",
    "baseURL = 'ftp://gdo-dcp.ucllnl.org/pub/dcp/archive/cmip5/hydro/BCSD_mon_VIC_nc/ccsm4_rcp26_r1i1p1/'\n",
    "baseURL2 = 'ftp://gdo-dcp.ucllnl.org/pub/dcp/archive/cmip5/hydro/BCSD_mon_forc_nc/ccsm4_rcp26_r1i1p1/'\n",
    "roURL = baseURL + \"conus_c5.ccsm4_rcp26_r1i1p1.monthly.total_runoff.{}.nc\".format(year)\n",
    "prURL = baseURL2 + \"conus_c5.ccsm4_rcp26_r1i1p1.monthly.pr.{}.nc\".format(year)\n",
    "etURL = baseURL + \"conus_c5.ccsm4_rcp26_r1i1p1.monthly.et.{}.nc\".format(year)\n",
    "smURL = baseURL + \"conus_c5.ccsm4_rcp26_r1i1p1.monthly.smc.{}.nc\".format(year)\n",
    "\n",
    "#These lines fix an issue with slow network connections\n",
    "import socket\n",
    "socket.setdefaulttimeout(30)\n",
    "\n",
    "#Loop through each file and create an annual sum array; add it to a dictionary\n",
    "dataDict = {}\n",
    "url = roURL\n",
    "print \"...downloading data from \" + url\n",
    "#Retrieve the data file from the ftp server\n",
    "urllib.urlretrieve(url,\"tmpData.nc\")\n",
    "\n",
    "#Convert to netCDF object\n",
    "nc = netCDF4.Dataset(\"tmpData.nc\",mode='r')\n",
    "\n",
    "#Add the lats and lons array to the dictionary\n",
    "dataDict[\"lats\"] = nc.variables['latitude'][:]\n",
    "dataDict[\"lons\"] = nc.variables['longitude'][:]\n",
    "\n",
    "#Get the parameter name and its values\n",
    "param_name = nc.variables.keys()[-1]\n",
    "param_vals = nc.variables.values()[-1]\n",
    "\n",
    "#Collapse the monthly values into a single array\n",
    "dataDict[param_name] = param_vals[:,:,:].sum(axis=0)\n",
    "\n",
    "#Close the nc object\n",
    "nc.close()\n",
    "\n",
    "#Delete the nc file\n",
    "os.remove(\"tmpData.nc\")\n",
    "\n",
    "#Update\n",
    "urllib.urlcleanup()\n",
    "print \"....complete\"\n",
    "\n",
    "#Write array values as X,Y table\n",
    "#Create lons and lats array\n",
    "lons = dataDict[\"lons\"]\n",
    "lats = dataDict[\"lats\"]\n",
    "\n",
    "#Initialize the index to retrieve FIPS codes\n",
    "idxFIPS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-1.11.0-py2.py3-none-any.whl (66kB)\n",
      "Installing collected packages: geopy\n",
      "Successfully installed geopy-1.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "pip.main(['install','geopy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
